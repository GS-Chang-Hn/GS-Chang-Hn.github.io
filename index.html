<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="icon" type="image/x-icon" href="picture/title.ico" />
<title>常兆斌 (Zhaobin Chang)</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>常兆斌 (Zhaobin Chang) 🏕️🎢🏸🎮🃏👨‍💻</h1>
</div>
<table class="imgtable"><tr>
<!-- 第一列 -->
<td><a href="https://gs-chang-hn.github.io/"><img src="changzhaobin.jpg" alt="alt text" width="135px" /></a>&nbsp;</td>
<!-- 第二列 -->
<td align="left">
<p>我目前在<a href="https://xxxy.lzu.edu.cn/">兰州大学</a><a href="https://xxxy.lzu.edu.cn/">信息科学与工程学院</a>攻读博士学位👨‍🎓。</p>  
<p>我的研究兴趣主要包括😎😎😎: <br />
✔️ <b>小样本语义分割 (Few-shot Semantic Segmentation (FSS))</b> 
<ul>
  <li>小样本学习 (Few-shot Learning) </li>
  <li>语义分割 (Semantic Segmentation) 、医学图像分析(Medical Image Analysis)</li>
</ul>
🔜 <b>深度学习中的可解释性 (Interpretability in Deep Learning)</b> </p>
</td>
<!-- 第三列 -->
<td align="left">
  <ul><li><a href="1510998508@qq.com">📧 [E-mail]</a></li></ul>
  <ul><li><a href="https://www.researchgate.net/profile/Zhaobin-Chang">🎓 [ResearchGate]</a></li></ul>
  <ul><li><a href="https://github.com/GS-Chang-Hn/">📥 [GitHub]</a></li></ul>
  <ul><li><a href="https://orcid.org/0000-0002-1574-979X">🆔 [ORCID]</a></li></ul>
</td>
</tr></table>

<h2>教育以及工作经历</h2> 
<ul>
<li><p>2021.09 ~ 2025.05: 兰州大学, 信息科学与工程学院，博士， [导师: 路永钢教授</a>]</p></li>
<li><p>2020.7 ~ 2021.7: 中国电子科技集团第30所 </p></li>
<li><p>2017.09 ~ 2020.07: 兰州理工大学, 计算机与通信学院, 硕士，[导师: 赵宏教授</a>] </p></li>
<li><p>2013.09 ~ 2017.07: 兰州理工大学, 计算机与通信学院, 学士 </p></li>
</ul>

<h2>学术论文</h2>
  <h4>2025</h4>
    <ul><li><p><a href="https://ieeexplore.ieee.org/">MIP-CLIP: Multimodal Independent Prompt CLIP for Action Recognition</a> <br />
    Xiong Gao, <b>Zhaobin Chang</b>, Dongyi Kong, Huiyu Zhou, and Yonggang Lu <br />
    <i>IEEE Transactions on Multimedia  (<b>TMM</b>), 2025. </i> <br /> 
    <span class="special">[CCF B类期刊, SCI 1区, IF=8.4]</span></a>
    </p></li></ul>
  
  <h4>2024</h4>
    <ul><li><p><a href="https://ieeexplore.ieee.org/document/10414072">DRNet: Disentanglement and Recombination Network for Few-Shot Semantic Segmentation</a> <br />
    <b>Zhaobin Chang</b>, Xiong Gao,  Na Li, Huiyu Zhou, and Yonggang Lu <br />
    <i>IEEE Transactions on Circuits and Systems for Video Technology  (<b>TCSVT</b>), 2024. </i> <br /> 
    <span class="special">[CCF B类期刊, SCI 1区, IF=8.3]</span></a>
    </p></li></ul>
  
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s00371-024-03747-y">Multi-prototype collaborative perception enhancement network for few-shot semantic segmentation</a> <br />
    <b>Zhaobin Chang</b>, Xiong Gao, Dongyi Kong, Na Li, and Yonggang Lu <br />
    <i>The Visual Computer, 2024. </i> <br />
    <span class="special">[SCI 3区, IF=3.0]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://doi.org/10.1016/j.knosys.2024.111852">CANet: Comprehensive Attention Network for video-based action recognition</a> <br />
    Xiong Gao, <b>Zhaobin Chang</b>, Xingcheng Ran, and Yonggang Lu <br />
    <i>Knowledge-Based Systems, 2024. </i> <br /> 
    <span class="special">[CCF C类期刊，SCI 1区, IF=7.2]</span> </a>
    </p></li></ul>
    
    <ul><li><p><a href="https://ieeexplore.ieee.org/document/10821766">Prediction of Protein-Peptide Binding Residues via Pre-Trained Protein Language Model and Progressive Contrastive Representation Learning</a> <br />
    Jianwei Li, Yonggang Lu, Xiangwen Wang, and <b>Zhaobin Chang</b> <br />
    <i>2024 IEEE International Conference on Bioinformatics and Biomedicine (<b>BIBM</b>), 2024. </i> <br />
    <span class="special">[CCF B类会议]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://doi.org/10.1016/j.compeleceng.2024.109855">High frequency domain enhancement and channel attention module for multi-view stereo</a> <br />
    Yongjuan Yang, Jie Cao, Hong Zhao, <b>Zhaobin Chang</b>, and Weijie Wang<br />
    <i>Computers & Electrical Engineering, 2024. </i> <br /> 
    <span class="special">[SCI 3区, IF=4.0]</span> </a>
    </p></li></ul>

    <ul><li><p><a href="https://ieeexplore.ieee.org/document/10634108">Diff-KT: Text-Driven Image Editing by Knowledge Enhancement and Mask Transformer</a> <br />
    Hong Zhao, Wengai Li, <b>Zhaobin Chang</b>, and Ce Yang <br />
    <i>IEEE Access, 2024. </i> <br />
    <span class="special">[SCI 3区, IF=3.4]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://ieeexplore.ieee.org/document/10899730">Self-Consistent Semantic Feature Extraction of Image Object Based on Contrastive Learning</a> <br />
    SHanyuan Liu, <b>Zhaobin Chang</b>, and Yonggang Lu <br />
    <i>2024 7th International Conference on Algorithms, Computing and Artificial Intelligence(<b>ACAI</b>), 2024. </i> <br /> 
    <span class="special">[EI 会议]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://peerj.com/articles/cs-2261/">PSA-HWT: Handwritten Font Generation Based on Pyramid Squeeze Attention</a> <br />
    Hong Zhao, Jinhai Huang, Wengai Li, <b>Zhaobin Chang</b>, and Weijie Wang <br />
    <i>PeerJ Computer Science, 2024. </i> <br />
    <span class="special">[SCI 4区, IF=3.5]</span> </a>
    </p></li></ul>
  
  <h4>2023</h4>
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s10489-023-04937-2">Simple yet effective joint guidance learning for few-shot semantic segmentation</a> <br />
    <b>Zhaobin Chang</b>, Yonggang Lu, Xiong Gao, Xingcheng Ran, and Hong Zhao <br />
    <i>Applied Intelligence, 2023. </i> <br />
    <span class="special">[SCI 2区期刊, IF=3.4]</span> </a>
    </p></li></ul>
    
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s10489-023-04937-2">Few-Shot Semantic Segmentation: A Review on Recent Approaches</a> <br />
    <b>Zhaobin Chang</b>, Yonggang Lu, Xingcheng Ran, Xiong Gao, and Xiangwen Wang <br />
    <i>Neural Computing and Applications, 2023. </i> <br />
    <span class="special">[SCI 3区期刊, IF=4.5]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://doi.org/10.1016/j.displa.2023.102569">Fine-gained Motion Enhancement for action recognition: Focusing on action-related regions</a> <br />
    Xiong Gao, <b>Zhaobin Chang</b>, Yande Li, Xingcheng Ran, Wei Ke, and Yonggang Lu <br />
    <i>Displays, 2023. </i> <br />
    <span class="special">[SCI 2区期刊, IF=3.7]</span> </a>
    </p></li></ul>
  
  <h4>2022</h4>
    <ul><li><p><a href="https://doi.org/10.1016/j.engappai.2022.105431">MGNet: Mutual-guidance network for few-shot semantic segmentation</a> <br />
    <b>Zhaobin Chang</b>, Yonggang Lu, Xiangwen Wang, and Xingcheng Ran <br />
    <i>Engineering Applications of Artificial Intelligence (<b>EAAI</b>), 2022. </i> <br />
    <span class="special">[CCF C类期刊, SCI 2区, IF=7.5]</a>
    </p></li></ul>

<h2>荣誉奖励</h2>
<ul>
<li><p>入选2024年度 (首批) "中国科协青年人才托举工程"博士生专项计划 <span class="special">[托举学会为: 中国计算机学会]</span> (2025.01) </p></li>
<li><p>硕士研究生国家奖学金 <span class="special">(2019.12) </p></li>
<li><p>兰州理工大学优秀学位论文（证书编号：YS2020007） (2020.07.15) </p></li>
<li><p>甘肃省优秀硕士学位论文（证书编号：YS2020052） (2021.03.18) </p></li>
<li><p>《电讯技术》十佳联络员 (2023-2024年度) </p></li>
</ul>
  
<h2>发明专利</h2>
<ul>
<li><p>一种基于特征分离与重组的小样本图像语义分割方法 <br />
<b>常兆斌</b> <br />
国家发明专利, 已授权，202310858480.4 </p>
</ul>



<h2>课题项目</h2>
<ul><li><p>基于小样本的深度学习图像语义分割研究 (No. 23JRRA1133), 2023.07-2024.06 <br />
<b>主持</b>;  经费:4.00万元 <br />
<b>项目来源：</b>甘肃省自然科学基金项目（优博项目） <br /></p></li></ul>
  
<ul><li><p>中国科协青年人才托举工程博士生专项计划学术经费, 2025.01-2026.12 <br />
<b>主持</b>;  经费:4.00万元 <br />
<b>项目来源：</b>中国科协 <br /></p></li></ul>

<ul><li><p>大模型背景下特征解纠缠和特征对齐在基于小样本的计算机视觉任务中的研究与示范 (No. 24JRRA388), 2024.08-2027.07 <br />
<b>课题骨干</b>;  经费:60.00万元 <br />
<b>项目来源：</b>甘肃省基础研究创新群体项目 <br /></p></li></ul>

<ul><li><p>人工智能技术及其在智慧交通中的应用研究 (No. GSHZTS2022-2), 2022.12-2024.11 <br />
<b>课题骨干</b>;  经费:25.00万元 <br />
<b>项目来源：</b>甘肃海智计划特色示范项目 <br /></p></li></ul>


<h2>学术服务</h2>
<h4>期刊审稿</h4>
<ul>
<li><p>IEEE Transactions on Neural Networks and Learning Systems </p></li>
<li><p>IEEE Transactions on Multimedia </p></li>
<li><p>IEEE Transactions on Circuits and Systems for Video Technology </p></li>
<li><p>IEEE Transactions on Geoscience and Remote Sensing </p></li>
<li><p>IEEE Transactions on Artificial Intelligence </p></li>
<li><p>IEEE Transactions on Pattern Analysis and Machine Intelligence </p></li>
<li><p>Neurocomputing </p></li>
<li><p>Applied Intelligence </p></li>
<li><p>IEEE Transactions on Image Processing </p></li>
<li><p>The Journal of Supercomputing </p></li>
<li><p>Scientific Reports </p></li>
<li><p>Journal of Computer Networks and Communications </p></li>
<li><p>Neural Computing and Applications </p></li>
<li><p>Engineering Applications of Artificial Intelligence </p></li>
</ul>

<h2>网站访问统计 (自2025年2月起)</h2>
<a href="https://clustrmaps.com/site/1bxn1"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=4V6eYQ2IPE90W5uH_zCPr6SfzhrxmDDztM3gjnQ8ILE&cl=ffffff" /></a><br />
<!-- <br /><br /> -->
<!-- <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&color=119DF7&background=428FFF31&center=true&vCenter=true&random=false&width=435&lines=祝您在学术研究的道路上越走越远🛫🛫🛫！;不断取得新的突破和成就💪💪💪！" alt="Typing SVG" /> -->


<div id="footer">
<div id="footer-text">
<br>Page generated 2025-03-13, by <a href="https://gs-chang-hn.github.io/">Zhaobin Chang</a>.
</div>
</div>
</div>
</body>
</html>
