<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="icon" type="image/x-icon" href="picture/title.ico" />
<title>å¸¸å…†æ–Œ (Zhaobin Chang)</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>å¸¸å…†æ–Œ (Zhaobin Chang) ğŸ•ï¸ğŸ¢ğŸ¸ğŸ®ğŸƒğŸ‘¨â€ğŸ’»</h1>
</div>
<table class="imgtable"><tr>
<!-- ç¬¬ä¸€åˆ— -->
<td><a href="https://gs-chang-hn.github.io/"><img src="picture/changzhaobin.jpg" alt="alt text" width="135px" /></a>&nbsp;</td>
<!-- ç¬¬äºŒåˆ— -->
<td align="left">
<p>æˆ‘ç›®å‰åœ¨<a href="http://www.hfut.edu.cn/">å…°å·å¤§å­¦</a><a href="https://xxxy.lzu.edu.cn/">ä¿¡æ¯ç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢</a>æ”»è¯»åšå£«å­¦ä½ğŸ‘¨â€ğŸ“ã€‚</p>  
<p>æˆ‘çš„ç ”ç©¶å…´è¶£ä¸»è¦åŒ…æ‹¬ğŸ˜ğŸ˜ğŸ˜: <br />
âœ”ï¸ <b>å°æ ·æœ¬è¯­ä¹‰åˆ†å‰² (Few-shot Semantic Segmentation (FSS))</b> 
<ul>
  <li>å°æ ·æœ¬å­¦ä¹  (Few-shot Learning) </li>
  <li>è¯­ä¹‰åˆ†å‰² (Semantic Segmentation) </li>
</ul>
ğŸ”œ <b>æ·±åº¦å­¦ä¹ ä¸­çš„å¯è§£é‡Šæ€§ (Interpretability in Deep Learning)</b> </p>
</td>
<!-- ç¬¬ä¸‰åˆ— -->
<td align="left">
  <ul><li><a href="changzhb21@lzu.edu.cn">ğŸ“§ [E-mail]</a></li></ul>
  <ul><li><a href="https://www.researchgate.net/profile/Zhaobin-Chang">ğŸ“ [ResearchGate]</a></li></ul>
  <ul><li><a href="https://github.com/GS-Chang-Hn/">ğŸ“¥ [GitHub]</a></li></ul>
  <ul><li><a href="https://orcid.org/0000-0002-1574-979X">ğŸ†” [ORCID]</a></li></ul>
</td>
</tr></table>

<h2>æ•™è‚²ä»¥åŠå·¥ä½œç»å†</h2> 
<ul>
<li><p>2021.09 ~ ç°åœ¨: å…°å·å¤§å­¦, ä¿¡æ¯ç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢, åœ¨è¯»åšå£« [å¯¼å¸ˆ: è·¯æ°¸é’¢æ•™æˆ</a>]</p></li>
<li><p>2020.7 ~ 2021.7: ä¸­å›½ç”µå­ç§‘æŠ€é›†å›¢ç¬¬30æ‰€ </p></li>
<li><p>2017.09 ~ 2020.07: å…°å·ç†å·¥å¤§å­¦, è®¡ç®—æœºä¸é€šä¿¡å­¦é™¢, ç¡•å£«ï¼Œ[å¯¼å¸ˆ: èµµå®æ•™æˆ</a>] </p></li>
<li><p>2013.09 ~ 2017.07: å…°å·ç†å·¥å¤§å­¦, è®¡ç®—æœºä¸é€šä¿¡å­¦é™¢, å­¦å£« </p></li>
</ul>

<h2>å­¦æœ¯è®ºæ–‡</h2>
  <h4>2025</h4>
    <ul><li><p><a href="https://XXXXXXX">Federated Causally Invariant Feature Learning</a> <br /> 
    <b>Zhaobin Chang</b>, Kui Yu, Lizhen Cui, Han Yu, and Xiaoxiao Li <br />
    <i>Proceedings of the 39th AAAI Conference on Artificial Intelligence (<b>AAAI'25</b>), 2025. </i> <br /> 
    <span class="special">[CCF Aç±»ä¼šè®®, å½•ç”¨ç‡çº¦23.40%]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/FedCIFL(2025).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/FedCIFL">[Code]</a><a href="pdf/FedCIFL-app.pdf">[Appendix]</a>
    </p></li></ul>

    <ul><li><p><a href="https://XXXXX">FedECE: Federated Estimation of Causal Effect Based on Causal Graphical Modelling</a> <br />
    Yongsheng Zhao, Kui Yu, Guodu Xiang, <b>Zhaobin Chang</b>, and Fuyuan Cao <br />
    <i>IEEE Transactions on Artificial Intelligence (<b>TAI</b>), 2025. </i> <br />
    <span class="special">[EIæœŸåˆŠ]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/FedECE(2025).pdf">[PDF]</a><a href="pdf/FedECE-supp.pdf">[Supplementary Material]</a>
    </p></li></ul>
  
  <h4>2024</h4>
    <ul><li><p><a href="https://ieeexplore.ieee.org/document/10414072">DRNet: Disentanglement and Recombination Network for Few-Shot Semantic Segmentation</a> <br />
    <b>Zhaobin Chang</b>, Xiong Gao,  Na Li, Huiyu Zhou, and Yonggang Lu <br />
    <i>IEEE Transactions on Circuits and Systems for Video Technology  (<b>TCSVT</b>), 2024. </i> <br /> 
    <span class="special">[CCF Bç±»æœŸåˆŠ, SCI 1åŒº, IF=8.3]</span></a>
    </p></li></ul>
  
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s00371-024-03747-y">Multi-prototype collaborative perception enhancement network for few-shot semantic segmentation</a> <br />
    <b>Zhaobin Chang</b>, Xiong Gao, Dongyi Kong, Na Li, and Yonggang Lu <br />
    <i>The Visual Computer, 2024. </i> <br />
    <span class="special">[SCI 3åŒº, IF=3.0]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://doi.org/10.1016/j.knosys.2024.111852">CANet: Comprehensive Attention Network for video-based action recognition</a> <br />
    Xiong Gao, <b>Zhaobin Chang</b>, Xingcheng Ran, and Yonggang Lu <br />
    <i>Knowledge-Based Systems, 2024. </i> <br /> 
    <span class="special">[CCF Cç±»æœŸåˆŠï¼ŒSCI 1åŒº, IF=7.2]</span> </a>
    </p></li></ul>
    
    <ul><li><p><a href="https://ieeexplore.ieee.org/document/10821766">Prediction of Protein-Peptide Binding Residues via Pre-Trained Protein Language Model and Progressive Contrastive Representation Learning</a> <br />
    Jianwei Li, Yonggang Lu, Xiangwen Wang, and <b>Zhaobin Chang</b> <br />
    <i>2024 IEEE International Conference on Bioinformatics and Biomedicine (<b>BIBM</b>), 2024. </i> <br />
    <span class="special">[CCF Bç±»ä¼šè®®]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s00530-024-01537-z">Collaborative multi-knowledge distillation under the influence of softmax regression representation</a> <br />
    Hong Zhao, Kangping Chen, and <b>Zhaobin Chang</b><br />
    <i>Multimedia Systems, 2024. </i> <br /> 
    <span class="special">[SCI 4åŒº, IF=3.5]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://ieeexplore.ieee.org/document/10899730">Self-Consistent Semantic Feature Extraction of Image Object Based on Contrastive Learning</a> <br />
    SHanyuan Liu, <b>Zhaobin Chang</b>, and Yonggang Lu <br />
    <i>2024 7th International Conference on Algorithms, Computing and Artificial Intelligence(<b>ACAI</b>), 2024. </i> <br /> 
    <span class="special">[EI ä¼šè®®]</span> </a>
    </p></li></ul>
  
  <h4>2023</h4>
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s10489-023-04937-2">Simple yet effective joint guidance learning for few-shot semantic segmentation</a> <br />
    <b>Zhaobin Chang</b>, Yonggang Lu, Xiong Gao, Xingcheng Ran, and Hong Zhao <br />
    <i>Applied Intelligence, 2023. </i> <br />
    <span class="special">[SCI 2åŒºæœŸåˆŠ, IF=3.4]</span> </a>
    </p></li></ul>
    
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s10489-023-04937-2">Few-Shot Semantic Segmentation: A Review on Recent Approaches</a> <br />
    <b>Zhaobin Chang</b>, Yonggang Lu, Xingcheng Ran, Xiong Gao, and Xiangwen Wang <br />
    <i>Neural Computing and Applications, 2023. </i> <br />
    <span class="special">[SCI 3åŒºæœŸåˆŠ, IF=4.5]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://doi.org/10.1016/j.displa.2023.102569">Fine-gained Motion Enhancement for action recognition: Focusing on action-related regions</a> <br />
    Xiong Gao, <b>Zhaobin Chang</b>, Yande Li, Xingcheng Ran, Wei Ke, and Yonggang Lu <br />
    <i>Displays, 2023. </i> <br />
    <span class="special">[SCI 2åŒºæœŸåˆŠ, IF=3.7]</span> </a>
    </p></li></ul>
  
  <h4>2022</h4>
    <ul><li><p><a href="https://doi.org/10.1016/j.engappai.2022.105431">MGNet: Mutual-guidance network for few-shot semantic segmentation</a> <br />
    <b>Zhaobin Chang</b>, Yonggang Lu, Xiangwen Wang, and Xingcheng Ran <br />
    <i>Engineering Applications of Artificial Intelligence (<b>EAAI</b>), 2022. </i> <br />
    <span class="special">[CCF Cç±»æœŸåˆŠ, SCI 2åŒº, IF=7.5]</a>
    </p></li></ul>

<h2>è£èª‰å¥–åŠ±</h2>
<ul>
<li><p>å…¥é€‰2024å¹´åº¦ (ç¬¬ä¸€å±Š) ä¸­å›½ç§‘åé’å¹´äººæ‰æ‰˜ä¸¾å·¥ç¨‹åšå£«ç”Ÿä¸“é¡¹è®¡åˆ’ <span class="special">[æ‰˜ä¸¾å­¦ä¼šä¸º: ä¸­å›½è®¡ç®—æœºå­¦ä¼š]</span> (2025.01) </p></li>
<li><p>ç¡•å£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ <span class="special">[æ’å: 3rd / 15]</span> (2020.11) </p></li>
<li><p>åšå£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ <span class="special">[æ’å: 1st / 6]</span> (2024.09) </p></li>
<li><p>FL@FM-NeurIPS'24 ä¼˜ç§€å­¦ç”Ÿè®ºæ–‡å¥– (2024.10) </p></li>
<li><p>å®‰å¾½çœä¼˜ç§€æ¯•ä¸šç”Ÿç§°å· (2021.05) </p></li>
<li><p>åˆè‚¥å·¥ä¸šå¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿç§°å· (2021.05) </p></li>
<li><p>2021å¹´åº¦å®‰å¾½çœè®¡ç®—æœºå­¦ä¼šä¼˜ç§€ç¡•å£«è®ºæ–‡å¥– (2021.12) </p></li>
<li><p>2022å¹´åº¦å®‰å¾½çœä¼˜ç§€ç¡•å£«å­¦ä½è®ºæ–‡å¥– (2022.12) </p></li>
<li><p>2023å¹´åº¦å›½å®¶ç•™å­¦åŸºé‡‘å§”å…¬æ´¾ç•™å­¦å¥–å­¦é‡‘ (2023.08) </p></li>
<li><p>2023å¹´åº¦å®‰å¾½çœæ–°æ—¶ä»£è‚²äººè´¨é‡å·¥ç¨‹é¡¹ç›®-ç ”ç©¶ç”Ÿå­¦æœ¯åˆ›æ–°: é¢å‘åŒ»ç–—æ•°æ®çš„è”é‚¦å› æœå‘ç° (No. 2023xscx012), ç”³æŠ¥è´Ÿè´£äºº </p></li>
<li><p>2024å¹´åº¦å®‰å¾½çœæ–°æ—¶ä»£è‚²äººè´¨é‡å·¥ç¨‹é¡¹ç›®-ç ”ç©¶ç”Ÿâ€œåˆ›æ–°åˆ›ä¸šä¹‹æ˜Ÿâ€ (No. 2024cxcyzx037)</p></li>
</ul>
  

<!--<h2>å‘æ˜ä¸“åˆ©</h2>-->
<!--<ul>-->
<!--<li><p>åŸºäºå›¢åˆ’åˆ†çš„é™æ€å……ç”µæ¡©éƒ¨ç½²æ–¹æ³• <br />-->
<!--é’Ÿè, <b>å¾çˆ±æ˜†</b>, å¥æ™“ç‡•, å¼ è‰ºé›¯<br />-->
<!--å›½å®¶å‘æ˜ä¸“åˆ©, å…¬å¼€å·:CN109872070A</p>-->
<!--</li>-->
<!--</ul>-->


<h2>è¯¾é¢˜é¡¹ç›®</h2>
<ul><li><p>é¢å‘éšç§ä¿æŠ¤æ•°æ®çš„è”é‚¦å› æœå…³ç³»æ¨æ–­ç®—æ³•ç ”ç©¶ (No. 62376087), 2024.01-2027.12 <br />
<b>é¡¹ç›®éª¨å¹²</b>;  ç»è´¹:51ä¸‡å…ƒ <br />
å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›® <br /></p></li></ul>

<ul><li><p>è·¨åª’ä½“å› æœæ¨æ–­ä¸å¯ä¿¡æœºå™¨å­¦ä¹  (No. 2021ZD0111801), 2021.12-2025.11 <br />
<b>å­è¯¾é¢˜éª¨å¹²</b>;  ç»è´¹:100ä¸‡å…ƒ <br />
ç§‘æŠ€éƒ¨ç§‘æŠ€åˆ›æ–°2030-â€œæ–°ä¸€ä»£äººå·¥æ™ºèƒ½â€é‡å¤§é¡¹ç›® <br /></p></li></ul>

<ul><li><p>å¸¸è¯†çŸ¥è¯†å­¦ä¹ ä¸å› æœåˆ†æ (No. 2020AAA0106100), 2020.11-2024.10 <br />
<b>è¯¾é¢˜éª¨å¹²</b>;  ç»è´¹:180ä¸‡å…ƒ <br />
ç§‘æŠ€éƒ¨ç§‘æŠ€åˆ›æ–°2030-â€œæ–°ä¸€ä»£äººå·¥æ™ºèƒ½â€é‡å¤§é¡¹ç›® <br /></p></li></ul>


<h2>å­¦æœ¯æœåŠ¡</h2>
<h4>æœŸåˆŠå®¡ç¨¿</h4>
<ul>
<li><p>IEEE Transactions on Knowledge and Data Engineering </p></li>
<li><p>IEEE Transactions on Neural Networks and Learning Systems </p></li>
<li><p>ACM Transactions on Knowledge Discovery from Data </p></li>
<li><p>IEEE Transactions on Circuits and Systems for Video Technology </p></li>
<li><p>IEEE Transactions on Signal and Information Processing over Networks </p></li>
<li><p>IEEE Transactions on Emerging Topics in Computational Intelligence </p></li>
<li><p>Machine Learning </p></li>
<li><p>Neurocomputing </p></li>
<li><p>Applied Intelligence </p></li>
<li><p>International Journal of Machine Learning and Cybernetics </p></li>
<li><p>The Journal of Supercomputing </p></li>
<li><p>Intelligent Automation and Soft Computing </p></li>
<li><p>CMC-Computers Materials & Continua </p></li>
<li><p>Neural Processing Letters </p></li>
</ul>

<h4>ä¼šè®®å®¡ç¨¿</h4>
<ul>
  <li><p>International Conference on Machine Learning (ICML'25), PC Member </p></li>
  <li><p>International Conference on Learning Representations (ICLR'25), PC Member </p></li>
  <li><p>Association for the Advancement of Artificial Intelligence (AAAI'24-25), PC Member </p></li>
  <li><p>International Joint Conference on Artificial Intelligence (IJCAI'24-25), PC Member </p></li>
  <li><p>The International Workshop on Federated Learning in the Age of Foundation Models (FL@FM-NeurIPS'23), PC Member </p></li>
  <li><p>The International Workshop on Federated Foundation Models for the Web 2024 (FL@FM-TheWebConf'24), PC Member </p></li>
  <li><p>The International Workshop on Trustworthy Federated Learning in Conjunction with IJCAI 2023 (FL-IJCAI'23), PC Member </p></li>
  <li><p>The International Workshop on Federated Learning and Foundation Models (FL@FM-ICME'24), PC Member </p></li>
</ul>

<h2>ç½‘ç«™è®¿é—®ç»Ÿè®¡ (è‡ª2025å¹´2æœˆèµ·)</h2>
<a href="https://clustrmaps.com/site/1bxn1"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=4V6eYQ2IPE90W5uH_zCPr6SfzhrxmDDztM3gjnQ8ILE&cl=ffffff" /></a><br />
<!-- <br /><br /> -->
<!-- <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&color=119DF7&background=428FFF31&center=true&vCenter=true&random=false&width=435&lines=ç¥æ‚¨åœ¨å­¦æœ¯ç ”ç©¶çš„é“è·¯ä¸Šè¶Šèµ°è¶Šè¿œğŸ›«ğŸ›«ğŸ›«ï¼;ä¸æ–­å–å¾—æ–°çš„çªç ´å’Œæˆå°±ğŸ’ªğŸ’ªğŸ’ªï¼" alt="Typing SVG" /> -->


<div id="footer">
<div id="footer-text">
<br>Page generated 2025-03-13, by <a href="https://xianjie-guo.github.io/">Zhaobin Chang</a>.
</div>
</div>
</div>
</body>
</html>
